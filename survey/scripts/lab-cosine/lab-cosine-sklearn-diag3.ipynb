{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ffc37db9-080c-413c-9499-ef151074ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b226ebff-8131-4b43-96a6-a6ecf33a8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1 = \"DBLog est un framework générique de capture de données de changement qui permet de capturer les modifications validées à partir d'une base de données en temps réel et de propager ces modifications aux consommateurs de downstream. Les journaux de transactions des bases de données sont la source des événements CDC. DBLog est un framework basé sur Java, capable de capturer les changements en temps réel et de faire des dumps. Nous utilisons Zookeeper pour stocker l'état lié au traitement des journaux et des dumps, et pour l'élection du leader. Pour utiliser DBLog, une base de données doit fournir un journal des modifications à partir d'un historique linéaire des modifications validées et ces conditions sont remplies par des systèmes tels que MySQL, PostgreSQL, MariaDB, etc. Le traitement de vidage a été intégré en utilisant SQL et JDBC, ne nécessitant que la mise en œuvre de la sélection de blocs et la mise à jour du filigrane. Le même code est utilisé pour MySQL et PostgreSQL et peut également être utilisé pour d'autres bases de données similaires. DBLog utilise une architecture active-passive. Une instance est active et les autres sont en veille passive. Nous utilisons Zookeeper pour l'élection du leader afin de déterminer l'instance active.\"\n",
    "#Resp 65 e 67:\n",
    "doc_2 = \"On a plusieurs bases de données (probablement distribuées), qui produisent des logs. Ces logs rentrent dans un service Apache Kafka.\"\n",
    "doc_3 = \"Je comprends que des données passent d'une source vers un log vers le sink. Je vois également les différentes BD utilisées. \"\n",
    "\n",
    "corpus = np.array([doc_1, doc_2, doc_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f35b20-18bb-4563-a75e-ff712445b5cb",
   "metadata": {},
   "source": [
    "### 1) Aplicar lowercase e remover caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7d708b90-8a3b-4820-82c5-2f3dcfc4b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    pattern = \"[{}]\".format(string.punctuation)\n",
    "    text = [word.lower() for word in text]\n",
    "    text = [[re.sub(pattern, \"\", word) for word in words.split()] for words in text]\n",
    "    text = [[word for word in words if len(word)>1] for words in text]    \n",
    "    text = [' '.join(words) for words in text]\n",
    "    return np.array(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ec2a0c77-c5a5-4514-af39-ec8272be8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['espresso is linkedins documentoriented timelineconsistent distributed data store clients fetching profile data read subset of fields of whole documents from espresso in different use cases there are three main parts of espresso routers storage nodes and cluster management routers receive requests from online clients and forward the requests to storage nodes routes also inspect uri to get the database name and look up the routing table for appropriate storage nodes to send requests to it also assembles the results and sends it back to clients storage node stores and serves documents provides transactions support for documents with the same partition key and maintains commit logs for replication espresso uses apache helix to monitor and maintain the cluster'\n",
      " 'can understand that there are several clients that communicate with routers just as there are several routers that communicate with storages nodes where each node contains database there is set of relays databus that communicate the storages all communications cited are bidirectional there are downstream clients that receive data from databus relays all components are located on the helix server'\n",
      " 'there are clients accessing something stored in cluster of storage nodes through routers dont really understand the databus relays and downstream parts'\n",
      " 'online client interacts with the router that passes information between the database and the client it also gets information from the helix that exchanges information from the database and downstream consumer the downstream consumer gets information in the database from databus relay as well']\n"
     ]
    }
   ],
   "source": [
    "corpus_clear = clear_text(corpus)\n",
    "print(corpus_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482ff6d-0afe-483b-a246-9e6f24c00688",
   "metadata": {},
   "source": [
    "### 2) Remover stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "312973ea-8f6b-442e-bec2-23c6df9ff054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def clear_stopwords(text, language):\n",
    "    filtered_text = []\n",
    "    for t in text:\n",
    "        words = [w for w in t.split() if not w in stopwords.words(language)]\n",
    "        words = ' '.join(words)\n",
    "        filtered_text.append(words)\n",
    "    return np.array(filtered_text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "db08e613-92cd-4591-8616-f8ed581aeeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['espresso is linkedins documentoriented timelineconsistent distributed data store clients fetching profile data read subset of fields of whole documents from espresso in different use cases there are three main parts of espresso routers storage nodes and cluster management routers receive requests from online clients and forward the requests to storage nodes routes also inspect uri to get the database name and look up the routing table appropriate storage nodes to send requests to it also assembles the results and sends it back to clients storage node stores and serves documents provides transactions support documents with the same partition key and maintains commit logs replication espresso uses apache helix to monitor and maintain the cluster'\n",
      " 'can understand that there are several clients that communicate with routers just there are several routers that communicate with storages nodes where each node contains database there is set of relays databus that communicate the storages all communications cited are bidirectional there are downstream clients that receive data from databus relays all components are located on the helix server'\n",
      " 'there are clients accessing something stored in cluster of storage nodes through routers dont really understand the databus relays and downstream parts'\n",
      " 'online client interacts with the router that passes information between the database and the client it also gets information from the helix that exchanges information from the database and downstream consumer the downstream consumer gets information in the database from databus relay well']\n"
     ]
    }
   ],
   "source": [
    "corpus_filtered = clear_stopwords(corpus_clear, \"french\")\n",
    "print(corpus_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55d884-a26c-4098-bb25-c9c13a465522",
   "metadata": {},
   "source": [
    "### Usando a biblioteca sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dc872573-b8a5-4c14-9d55-58f4e76dd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(matrix, tokens):\n",
    "    doc_names = [f'text_{i+1}' for i, _ in enumerate(matrix)]\n",
    "    df = pd.DataFrame(data=matrix, index=doc_names, columns=tokens)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a7a5fba4-ccdb-47aa-a2ff-9d6fe7182f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessing</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>and</th>\n",
       "      <th>apache</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>are</th>\n",
       "      <th>assembles</th>\n",
       "      <th>back</th>\n",
       "      <th>between</th>\n",
       "      <th>...</th>\n",
       "      <th>transactions</th>\n",
       "      <th>understand</th>\n",
       "      <th>up</th>\n",
       "      <th>uri</th>\n",
       "      <th>use</th>\n",
       "      <th>uses</th>\n",
       "      <th>well</th>\n",
       "      <th>where</th>\n",
       "      <th>whole</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        accessing  all  also  and  apache  appropriate  are  assembles  back  \\\n",
       "text_1          0    0     2    7       1            1    1          1     1   \n",
       "text_2          0    2     0    0       0            0    5          0     0   \n",
       "text_3          1    0     0    1       0            0    1          0     0   \n",
       "text_4          0    0     1    2       0            0    0          0     0   \n",
       "\n",
       "        between  ...  transactions  understand  up  uri  use  uses  well  \\\n",
       "text_1        0  ...             1           0   1    1    1     1     0   \n",
       "text_2        0  ...             0           1   0    0    0     0     0   \n",
       "text_3        0  ...             0           1   0    0    0     0     0   \n",
       "text_4        1  ...             0           0   0    0    0     0     1   \n",
       "\n",
       "        where  whole  with  \n",
       "text_1      0      1     1  \n",
       "text_2      1      0     2  \n",
       "text_3      0      0     0  \n",
       "text_4      0      0     1  \n",
       "\n",
       "[4 rows x 115 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorize = CountVectorizer()\n",
    "vector_matrix = vectorize.fit_transform(corpus_filtered)\n",
    "\n",
    "tokens = vectorize.get_feature_names()\n",
    "create_dataframe(vector_matrix.toarray(),tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4f27a489-3352-4e42-98fa-8e02a3e43dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>text_3</th>\n",
       "      <th>text_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.246008</td>\n",
       "      <td>0.431661</td>\n",
       "      <td>0.395190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_2</th>\n",
       "      <td>0.246008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>0.289496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_3</th>\n",
       "      <td>0.431661</td>\n",
       "      <td>0.422036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.251964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_4</th>\n",
       "      <td>0.395190</td>\n",
       "      <td>0.289496</td>\n",
       "      <td>0.251964</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text_1    text_2    text_3    text_4\n",
       "text_1  1.000000  0.246008  0.431661  0.395190\n",
       "text_2  0.246008  1.000000  0.422036  0.289496\n",
       "text_3  0.431661  0.422036  1.000000  0.251964\n",
       "text_4  0.395190  0.289496  0.251964  1.000000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
    "create_dataframe(cosine_similarity_matrix,['text_1','text_2','text_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9a53f-97a6-4426-aedc-7bbbd7b27c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
