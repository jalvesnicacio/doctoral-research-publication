{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffc37db9-080c-413c-9499-ef151074ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b226ebff-8131-4b43-96a6-a6ecf33a8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_1 = \"MetricsDB tem 3 componentes principais. O Cluster Manager é responsável por atribuir partições a servidores backend. HDFS é usado para armazenar mapeamentos de partições para servidores. Os servidores de back-end são responsáveis ​​pelo processamento de métricas para um pequeno número de partições. Cada servidor de back-end mantém as últimas duas horas de dados para todas as métricas na memória e verifica os dados na memória a cada duas horas para armazenamento durável, Blobstore. Os coordenadores são responsáveis ​​por rotear solicitações para todos os conjuntos de réplicas e valida que as restrições de quorum desejadas sejam atendidas. MetricsDB é compatível com várias zonas. MetricsDB tem um fator de replicação de três. O produtor Apache Kafka tem uma opção para solicitações em lote, o que nos ajudou a reduzir o número de solicitações para a fila e armazenamento.\"\n",
    "#Resp 12, 13,25,26 and 49:\n",
    "doc_12 = \"O Coordinator vai enviar as métricas para o Kafka. O Kafka possui 3 réplicas, cada uma delas contendo 1 Cluster manager e um Backend Server O Cluster manager vai trabalhar com os HDFS enquanto o Backend vai alimentar o Blobstore\"\n",
    "doc_13 = \"Arquitetura de integrações baseada em 4 camadas, onde, em uma delas, o Kafka recebe dados de um Coordinator e os envia a um servidor com 3 brokers, que, por sua vez, alimenta os sistemas HDFS e Blobstore.\"\n",
    "doc_25 = \"Informações que são coletadas são enviadas para clusters ou particões através do intermédio do Apache Kafta.\"\n",
    "doc_26 = \"Existem uma série de Replicas disponíveis para atendimento das Necessidades recebidas de Kafka. Cluster Manager é responsável por HDFS e Backend Servers responsável por Blobsotre\"\n",
    "\n",
    "diag_2 = \"Sempre que ocorre um evento no cliente do Spotify, ele é enviado para um dos gateways do Spotify, que o registra via syslog. Lá, é atribuído um carimbo de data / hora que é usado em todo o sistema de entrega de eventos. todos os dados precisam ser entregues a um cluster Hadoop localizado centralmente. Todos os dados entregues por meio de nosso serviço de entrega de eventos são gravados em HDFS. O File Tailer controla os arquivos de log em busca de novos eventos e os encaminha para o Event Delivery Service. Assim que obtiver a confirmação de que o evento foi recebido, a sua responsabilidade termina. O Event Delivery Service aceita eventos do Tailer, transforma-os em seu formato estruturado final e os encaminha para os Kafka Brokers. Event Delivery Service é construído como um microsserviço RESTful usando a estrutura Apollo e implementado usando a plataforma de orquestração Helios, um padrão de design comum no Spotify. Incorporar um produtor Kafka simples no serviço de entrega de eventos também provou ser fácil. O projeto Mirror Maker introduziu o espelhamento entre data centers e o projeto Camus pode ser usado para exportar eventos estruturados Avro para depósitos de hora em hora.\"\n",
    "diag_3 = \"DBLog é um framework genérico de Captura de Dados de Mudança (CDC)  que permite capturar mudanças confirmadas de um banco de dados em tempo real e propagar essas mudanças para consumidores downstream. Os logs de transações de bancos de dados são a origem dos eventos do CDC. DBLog é uma estrutura baseada em Java, capaz de capturar mudanças em tempo real e fazer dumps. Usamos o Zookeeper para armazenar o estado relacionado ao processamento de registro e dump e para a eleição do líder. Para usar DBLog, um banco de dados precisa fornecer um log de alterações a partir de um histórico linear de alterações confirmadas e essas condições são atendidas por sistemas como MySQL, PostgreSQL, MariaDB, etc. O processamento de dumps foi integrado ao sistema usando SQL e JDBC, exigindo apenas a implementação de seleção do bloco e a atualização da marca d'água. O mesmo código é usado para MySQL e PostgreSQL e também pode ser usado para outros bancos de dados semelhantes. DBLog usa uma arquitetura ativa-passiva. Uma instância está ativa e as outras estão em espera passiva. Aproveitamos o Zookeeper para a eleição do líder para determinar a instância ativa.\"\n",
    "\n",
    "corpus = np.array([diag_1, doc_12, doc_13, doc_25, doc_26, diag_2, diag_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f35b20-18bb-4563-a75e-ff712445b5cb",
   "metadata": {},
   "source": [
    "### 1) Aplicar lowercase e remover caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d708b90-8a3b-4820-82c5-2f3dcfc4b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    pattern = \"[{}]\".format(string.punctuation)\n",
    "    text = [word.lower() for word in text]\n",
    "    text = [[re.sub(pattern, \"\", word) for word in words.split()] for words in text]\n",
    "    text = [[word for word in words if len(word)>1] for words in text]    \n",
    "    text = [' '.join(words) for words in text]\n",
    "    return np.array(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec2a0c77-c5a5-4514-af39-ec8272be8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metricsdb tem componentes principais cluster manager responsável por atribuir partições servidores backend hdfs usado para armazenar mapeamentos de partições para servidores os servidores de backend são responsáveis \\u200b\\u200bpelo processamento de métricas para um pequeno número de partições cada servidor de backend mantém as últimas duas horas de dados para todas as métricas na memória verifica os dados na memória cada duas horas para armazenamento durável blobstore os coordenadores são responsáveis \\u200b\\u200bpor rotear solicitações para todos os conjuntos de réplicas valida que as restrições de quorum desejadas sejam atendidas metricsdb compatível com várias zonas metricsdb tem um fator de replicação de três produtor apache kafka tem uma opção para solicitações em lote que nos ajudou reduzir número de solicitações para fila armazenamento'\n",
      " 'coordinator vai enviar as métricas para kafka kafka possui réplicas cada uma delas contendo cluster manager um backend server cluster manager vai trabalhar com os hdfs enquanto backend vai alimentar blobstore'\n",
      " 'arquitetura de integrações baseada em camadas onde em uma delas kafka recebe dados de um coordinator os envia um servidor com brokers que por sua vez alimenta os sistemas hdfs blobstore'\n",
      " 'informações que são coletadas são enviadas para clusters ou particões através do intermédio do apache kafta'\n",
      " 'existem uma série de replicas disponíveis para atendimento das necessidades recebidas de kafka cluster manager responsável por hdfs backend servers responsável por blobsotre'\n",
      " 'sempre que ocorre um evento no cliente do spotify ele enviado para um dos gateways do spotify que registra via syslog lá atribuído um carimbo de data hora que usado em todo sistema de entrega de eventos todos os dados precisam ser entregues um cluster hadoop localizado centralmente todos os dados entregues por meio de nosso serviço de entrega de eventos são gravados em hdfs file tailer controla os arquivos de log em busca de novos eventos os encaminha para event delivery service assim que obtiver confirmação de que evento foi recebido sua responsabilidade termina event delivery service aceita eventos do tailer transformaos em seu formato estruturado final os encaminha para os kafka brokers event delivery service construído como um microsserviço restful usando estrutura apollo implementado usando plataforma de orquestração helios um padrão de design comum no spotify incorporar um produtor kafka simples no serviço de entrega de eventos também provou ser fácil projeto mirror maker introduziu espelhamento entre data centers projeto camus pode ser usado para exportar eventos estruturados avro para depósitos de hora em hora'\n",
      " 'dblog um framework genérico de captura de dados de mudança cdc que permite capturar mudanças confirmadas de um banco de dados em tempo real propagar essas mudanças para consumidores downstream os logs de transações de bancos de dados são origem dos eventos do cdc dblog uma estrutura baseada em java capaz de capturar mudanças em tempo real fazer dumps usamos zookeeper para armazenar estado relacionado ao processamento de registro dump para eleição do líder para usar dblog um banco de dados precisa fornecer um log de alterações partir de um histórico linear de alterações confirmadas essas condições são atendidas por sistemas como mysql postgresql mariadb etc processamento de dumps foi integrado ao sistema usando sql jdbc exigindo apenas implementação de seleção do bloco atualização da marca dágua mesmo código usado para mysql postgresql também pode ser usado para outros bancos de dados semelhantes dblog usa uma arquitetura ativapassiva uma instância está ativa as outras estão em espera passiva aproveitamos zookeeper para eleição do líder para determinar instância ativa']\n"
     ]
    }
   ],
   "source": [
    "corpus_clear = clear_text(corpus)\n",
    "print(corpus_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482ff6d-0afe-483b-a246-9e6f24c00688",
   "metadata": {},
   "source": [
    "### 2) Remover stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "312973ea-8f6b-442e-bec2-23c6df9ff054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def clear_stopwords(text, language):\n",
    "    filtered_text = []\n",
    "    for t in text:\n",
    "        words = [w for w in t.split() if not w in stopwords.words(language)]\n",
    "        words = ' '.join(words)\n",
    "        filtered_text.append(words)\n",
    "    return np.array(filtered_text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db08e613-92cd-4591-8616-f8ed581aeeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metricsdb tem componentes principais cluster manager responsável por atribuir partições servidores backend hdfs usado para armazenar mapeamentos de partições para servidores os servidores de backend são responsáveis \\u200b\\u200bpelo processamento de métricas para um pequeno número de partições cada servidor de backend mantém últimas duas horas de dados para todas métricas na memória verifica os dados na memória cada duas horas para armazenamento durável blobstore os coordenadores são responsáveis \\u200b\\u200bpor rotear solicitações para todos os conjuntos de réplicas valida que restrições de quorum desejadas sejam atendidas metricsdb compatível com várias zonas metricsdb tem um fator de replicação de três produtor apache kafka tem uma opção para solicitações em lote que nos ajudou reduzir número de solicitações para fila armazenamento'\n",
      " 'coordinator vai enviar métricas para kafka kafka possui réplicas cada uma delas contendo cluster manager um backend server cluster manager vai trabalhar com os hdfs enquanto backend vai alimentar blobstore'\n",
      " 'arquitetura de integrações baseada em camadas onde em uma delas kafka recebe dados de um coordinator os envia um servidor com brokers que por sua vez alimenta os sistemas hdfs blobstore'\n",
      " 'informações que são coletadas são enviadas para clusters ou particões através intermédio apache kafta'\n",
      " 'existem uma série de replicas disponíveis para atendimento das necessidades recebidas de kafka cluster manager responsável por hdfs backend servers responsável por blobsotre'\n",
      " 'sempre que ocorre um evento cliente spotify ele enviado para um dos gateways spotify que registra via syslog lá atribuído um carimbo de data hora que usado em todo sistema de entrega de eventos todos os dados precisam ser entregues um cluster hadoop localizado centralmente todos os dados entregues por meio de nosso serviço de entrega de eventos são gravados em hdfs file tailer controla os arquivos de log em busca de novos eventos os encaminha para event delivery service assim que obtiver confirmação de que evento foi recebido sua responsabilidade termina event delivery service aceita eventos tailer transformaos em seu formato estruturado final os encaminha para os kafka brokers event delivery service construído como um microsserviço restful usando estrutura apollo implementado usando plataforma de orquestração helios um padrão de design comum spotify incorporar um produtor kafka simples serviço de entrega de eventos também provou ser fácil projeto mirror maker introduziu espelhamento entre data centers projeto camus pode ser usado para exportar eventos estruturados avro para depósitos de hora em hora'\n",
      " 'dblog um framework genérico de captura de dados de mudança cdc que permite capturar mudanças confirmadas de um banco de dados em tempo real propagar essas mudanças para consumidores downstream os logs de transações de bancos de dados são origem dos eventos cdc dblog uma estrutura baseada em java capaz de capturar mudanças em tempo real fazer dumps usamos zookeeper para armazenar estado relacionado ao processamento de registro dump para eleição líder para usar dblog um banco de dados precisa fornecer um log de alterações partir de um histórico linear de alterações confirmadas essas condições são atendidas por sistemas como mysql postgresql mariadb etc processamento de dumps foi integrado ao sistema usando sql jdbc exigindo apenas implementação de seleção bloco atualização da marca dágua mesmo código usado para mysql postgresql também pode ser usado para outros bancos de dados semelhantes dblog usa uma arquitetura ativapassiva uma instância está ativa outras estão em espera passiva aproveitamos zookeeper para eleição líder para determinar instância ativa']\n"
     ]
    }
   ],
   "source": [
    "corpus_filtered = clear_stopwords(corpus_clear, \"english\")\n",
    "print(corpus_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55d884-a26c-4098-bb25-c9c13a465522",
   "metadata": {},
   "source": [
    "## Usando a biblioteca sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc872573-b8a5-4c14-9d55-58f4e76dd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(matrix, tokens):\n",
    "    doc_names = [f'text_{i+1}' for i, _ in enumerate(matrix)]\n",
    "    df = pd.DataFrame(data=matrix, index=doc_names, columns=tokens)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7a5fba4-ccdb-47aa-a2ff-9d6fe7182f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jalves/.local/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aceita</th>\n",
       "      <th>ajudou</th>\n",
       "      <th>alimenta</th>\n",
       "      <th>alimentar</th>\n",
       "      <th>alterações</th>\n",
       "      <th>ao</th>\n",
       "      <th>apache</th>\n",
       "      <th>apenas</th>\n",
       "      <th>apollo</th>\n",
       "      <th>aproveitamos</th>\n",
       "      <th>...</th>\n",
       "      <th>usar</th>\n",
       "      <th>vai</th>\n",
       "      <th>valida</th>\n",
       "      <th>verifica</th>\n",
       "      <th>vez</th>\n",
       "      <th>via</th>\n",
       "      <th>várias</th>\n",
       "      <th>zonas</th>\n",
       "      <th>zookeeper</th>\n",
       "      <th>últimas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aceita  ajudou  alimenta  alimentar  alterações  ao  apache  apenas  \\\n",
       "text_1       0       1         0          0           0   0       1       0   \n",
       "text_2       0       0         0          1           0   0       0       0   \n",
       "text_3       0       0         1          0           0   0       0       0   \n",
       "text_4       0       0         0          0           0   0       1       0   \n",
       "text_5       0       0         0          0           0   0       0       0   \n",
       "text_6       1       0         0          0           0   0       0       0   \n",
       "text_7       0       0         0          0           2   2       0       1   \n",
       "\n",
       "        apollo  aproveitamos  ...  usar  vai  valida  verifica  vez  via  \\\n",
       "text_1       0             0  ...     0    0       1         1    0    0   \n",
       "text_2       0             0  ...     0    3       0         0    0    0   \n",
       "text_3       0             0  ...     0    0       0         0    1    0   \n",
       "text_4       0             0  ...     0    0       0         0    0    0   \n",
       "text_5       0             0  ...     0    0       0         0    0    0   \n",
       "text_6       1             0  ...     0    0       0         0    0    1   \n",
       "text_7       0             1  ...     1    0       0         0    0    0   \n",
       "\n",
       "        várias  zonas  zookeeper  últimas  \n",
       "text_1       1      1          0        1  \n",
       "text_2       0      0          0        0  \n",
       "text_3       0      0          0        0  \n",
       "text_4       0      0          0        0  \n",
       "text_5       0      0          0        0  \n",
       "text_6       0      0          0        0  \n",
       "text_7       0      0          2        0  \n",
       "\n",
       "[7 rows x 273 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorize = CountVectorizer()\n",
    "vector_matrix = vectorize.fit_transform(corpus_filtered)\n",
    "\n",
    "tokens = vectorize.get_feature_names()\n",
    "create_dataframe(vector_matrix.toarray(),tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f27a489-3352-4e42-98fa-8e02a3e43dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diag_1</th>\n",
       "      <th>resp_1</th>\n",
       "      <th>resp_2</th>\n",
       "      <th>resp_3</th>\n",
       "      <th>resp_4</th>\n",
       "      <th>Diag_2</th>\n",
       "      <th>Diag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278093</td>\n",
       "      <td>0.405096</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.430628</td>\n",
       "      <td>0.577251</td>\n",
       "      <td>0.632167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_2</th>\n",
       "      <td>0.278093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289683</td>\n",
       "      <td>0.037689</td>\n",
       "      <td>0.307941</td>\n",
       "      <td>0.156360</td>\n",
       "      <td>0.103852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_3</th>\n",
       "      <td>0.405096</td>\n",
       "      <td>0.289683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>0.267615</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>0.434744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_4</th>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.037689</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046424</td>\n",
       "      <td>0.124461</td>\n",
       "      <td>0.131697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_5</th>\n",
       "      <td>0.430628</td>\n",
       "      <td>0.307941</td>\n",
       "      <td>0.267615</td>\n",
       "      <td>0.046424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300454</td>\n",
       "      <td>0.353663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_6</th>\n",
       "      <td>0.577251</td>\n",
       "      <td>0.156360</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>0.124461</td>\n",
       "      <td>0.300454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_7</th>\n",
       "      <td>0.632167</td>\n",
       "      <td>0.103852</td>\n",
       "      <td>0.434744</td>\n",
       "      <td>0.131697</td>\n",
       "      <td>0.353663</td>\n",
       "      <td>0.638832</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Diag_1    resp_1    resp_2    resp_3    resp_4    Diag_2    Diag_3\n",
       "text_1  1.000000  0.278093  0.405096  0.197642  0.430628  0.577251  0.632167\n",
       "text_2  0.278093  1.000000  0.289683  0.037689  0.307941  0.156360  0.103852\n",
       "text_3  0.405096  0.289683  1.000000  0.040032  0.267615  0.511529  0.434744\n",
       "text_4  0.197642  0.037689  0.040032  1.000000  0.046424  0.124461  0.131697\n",
       "text_5  0.430628  0.307941  0.267615  0.046424  1.000000  0.300454  0.353663\n",
       "text_6  0.577251  0.156360  0.511529  0.124461  0.300454  1.000000  0.638832\n",
       "text_7  0.632167  0.103852  0.434744  0.131697  0.353663  0.638832  1.000000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
    "create_dataframe(cosine_similarity_matrix,['Diag_1','resp_1','resp_2', 'resp_3', 'resp_4','Diag_2', 'Diag_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9a53f-97a6-4426-aedc-7bbbd7b27c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
