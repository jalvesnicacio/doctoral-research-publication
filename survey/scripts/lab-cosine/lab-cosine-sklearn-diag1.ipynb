{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc37db9-080c-413c-9499-ef151074ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b226ebff-8131-4b43-96a6-a6ecf33a8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.array([\"Sempre que ocorre um evento no cliente do Spotify, ele é enviado para um dos gateways do Spotify, que o registra via syslog. Lá, é atribuído um carimbo de data / hora que é usado em todo o sistema de entrega de eventos. todos os dados precisam ser entregues a um cluster Hadoop localizado centralmente. Todos os dados entregues por meio de nosso serviço de entrega de eventos são gravados em HDFS. O File Tailer controla os arquivos de log em busca de novos eventos e os encaminha para o Event Delivery Service. Assim que obtiver a confirmação de que o evento foi recebido, a responsabilidade termina. O Event Delivery Service aceita eventos do Tailer, transforma-os em seu formato estruturado final e os encaminha para os Kafka Brokers. Event Delivery Service é construído como um microsserviço RESTful usando a estrutura Apollo e implementado usando a plataforma de orquestração Helios, um padrão de design comum no Spotify. Incorporar um produtor Kafka simples no serviço de entrega de eventos também provou ser fácil. O projeto Mirror Maker introduziu o espelhamento entre data centers e o projeto Camus pode ser usado para exportar eventos estruturados Avro para depósitos de hora em hora.\",\n",
    "                   \"Quase nada.\",\n",
    "                   \n",
    "                   \n",
    "                   \n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f35b20-18bb-4563-a75e-ff712445b5cb",
   "metadata": {},
   "source": [
    "### 1) Aplicar lowercase e remover caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d708b90-8a3b-4820-82c5-2f3dcfc4b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    pattern = \"[{}]\".format(string.punctuation)\n",
    "    text = [word.lower() for word in text]\n",
    "    text = [[re.sub(pattern, \"\", word) for word in words.split()] for words in text]\n",
    "    text = [[word for word in words if len(word)>1] for words in text]    \n",
    "    text = [' '.join(words) for words in text]\n",
    "    return np.array(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2a0c77-c5a5-4514-af39-ec8272be8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sempre que ocorre um evento no cliente do spotify ele enviado para um dos gateways do spotify que registra via syslog lá atribuído um carimbo de data hora que usado em todo sistema de entrega de eventos todos os dados precisam ser entregues um cluster hadoop localizado centralmente todos os dados entregues por meio de nosso serviço de entrega de eventos são gravados em hdfs file tailer controla os arquivos de log em busca de novos eventos os encaminha para event delivery service assim que obtiver confirmação de que evento foi recebido responsabilidade termina event delivery service aceita eventos do tailer transformaos em seu formato estruturado final os encaminha para os kafka brokers event delivery service construído como um microsserviço restful usando estrutura apollo implementado usando plataforma de orquestração helios um padrão de design comum no spotify incorporar um produtor kafka simples no serviço de entrega de eventos também provou ser fácil projeto mirror maker introduziu espelhamento entre data centers projeto camus pode ser usado para exportar eventos estruturados avro para depósitos de hora em hora'\n",
      " 'quase nada']\n"
     ]
    }
   ],
   "source": [
    "corpus_clear = clear_text(corpus)\n",
    "print(corpus_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482ff6d-0afe-483b-a246-9e6f24c00688",
   "metadata": {},
   "source": [
    "### 2) Remover stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312973ea-8f6b-442e-bec2-23c6df9ff054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def clear_stopwords(text, language):\n",
    "    filtered_text = []\n",
    "    for t in text:\n",
    "        words = [w for w in t.split() if not w in stopwords.words(language)]\n",
    "        words = ' '.join(words)\n",
    "        filtered_text.append(words)\n",
    "    return np.array(filtered_text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db08e613-92cd-4591-8616-f8ed581aeeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sempre ocorre um evento no cliente do spotify ele enviado para um dos gateways do spotify registra via syslog lá atribuído um carimbo data hora usado em todo sistema entrega eventos todos os dados precisam ser entregues um cluster hadoop localizado centralmente todos os dados entregues por meio nosso serviço entrega eventos são gravados em hdfs file tailer controla os arquivos log em busca novos eventos os encaminha para event delivery service assim obtiver confirmação evento foi recebido responsabilidade termina event delivery service aceita eventos do tailer transformaos em seu formato estruturado final os encaminha para os kafka brokers event delivery service construído como um microsserviço restful usando estrutura apollo implementado usando plataforma orquestração helios um padrão design comum no spotify incorporar um produtor kafka simples no serviço entrega eventos também provou ser fácil projeto mirror maker introduziu espelhamento entre data centers projeto camus pode ser usado para exportar eventos estruturados avro para depósitos hora em hora'\n",
      " 'quase nada']\n"
     ]
    }
   ],
   "source": [
    "corpus_filtered = clear_stopwords(corpus_clear, \"french\")\n",
    "print(corpus_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd55d884-a26c-4098-bb25-c9c13a465522",
   "metadata": {},
   "source": [
    "### Usando a biblioteca sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc872573-b8a5-4c14-9d55-58f4e76dd6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(matrix, tokens):\n",
    "    doc_names = [f'text_{i+1}' for i, _ in enumerate(matrix)]\n",
    "    df = pd.DataFrame(data=matrix, index=doc_names, columns=tokens)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a5fba4-ccdb-47aa-a2ff-9d6fe7182f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aceita</th>\n",
       "      <th>apollo</th>\n",
       "      <th>arquivos</th>\n",
       "      <th>assim</th>\n",
       "      <th>atribuído</th>\n",
       "      <th>avro</th>\n",
       "      <th>brokers</th>\n",
       "      <th>busca</th>\n",
       "      <th>camus</th>\n",
       "      <th>carimbo</th>\n",
       "      <th>...</th>\n",
       "      <th>tailer</th>\n",
       "      <th>também</th>\n",
       "      <th>termina</th>\n",
       "      <th>todo</th>\n",
       "      <th>todos</th>\n",
       "      <th>transformaos</th>\n",
       "      <th>um</th>\n",
       "      <th>usado</th>\n",
       "      <th>usando</th>\n",
       "      <th>via</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aceita  apollo  arquivos  assim  atribuído  avro  brokers  busca  \\\n",
       "text_1       1       1         1      1          1     1        1      1   \n",
       "text_2       0       0         0      0          0     0        0      0   \n",
       "\n",
       "        camus  carimbo  ...  tailer  também  termina  todo  todos  \\\n",
       "text_1      1        1  ...       2       1        1     1      2   \n",
       "text_2      0        0  ...       0       0        0     0      0   \n",
       "\n",
       "        transformaos  um  usado  usando  via  \n",
       "text_1             1   7      2       2    1  \n",
       "text_2             0   0      0       0    0  \n",
       "\n",
       "[2 rows x 105 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorize = CountVectorizer()\n",
    "vector_matrix = vectorize.fit_transform(corpus_filtered)\n",
    "\n",
    "tokens = vectorize.get_feature_names()\n",
    "create_dataframe(vector_matrix.toarray(),tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f27a489-3352-4e42-98fa-8e02a3e43dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_1  text_2\n",
       "text_1     1.0     0.0\n",
       "text_2     0.0     1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_matrix = cosine_similarity(vector_matrix)\n",
    "create_dataframe(cosine_similarity_matrix,['text_1','text_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9a53f-97a6-4426-aedc-7bbbd7b27c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
